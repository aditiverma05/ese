{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OITMd8Ag6KfH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "# Tree / Boosting models\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "import lightgbm as lgb\n",
        "import xgboost as xgb\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_PATH = '/kaggle/input/mock-test-2-mse-2/train.csv'\n",
        "TEST_PATH  = '/kaggle/input/mock-test-2-mse-2/test.csv'\n",
        "train_df = pd.read_csv(TRAIN_PATH)\n",
        "test_df  = pd.read_csv(TEST_PATH)"
      ],
      "metadata": {
        "id": "PZD5p-Cc6st7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "id": "jmiN3B_z6vfu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TARGET_COL = 'Status' # Change to target col\n",
        "ID_COL     = 'id'"
      ],
      "metadata": {
        "id": "TFVUUz2d6xLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if train_df[TARGET_COL].isna().any():\n",
        "    target_mode = train_df[TARGET_COL].mode(dropna=True)[0]\n",
        "    train_df[TARGET_COL] = train_df[TARGET_COL].fillna(target_mode)"
      ],
      "metadata": {
        "id": "4Bd9kTfB6y8F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.describe()"
      ],
      "metadata": {
        "id": "idX2vzIh6077"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.info()"
      ],
      "metadata": {
        "id": "WsB0cHAK62ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(train_df[TARGET_COL])\n",
        "\n",
        "X = train_df.drop(columns=[c for c in [TARGET_COL, ID_COL] if c in train_df.columns])\n",
        "test_ids = test_df[ID_COL].copy()\n",
        "X_test = test_df.drop(columns=[ID_COL])"
      ],
      "metadata": {
        "id": "2lWZSH6464g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_cols = X.select_dtypes(include=['int64','float64']).columns\n",
        "cat_cols = X.select_dtypes(exclude=['int64','float64']).columns\n"
      ],
      "metadata": {
        "id": "YU6pw6WH67Ra"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='median')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, num_cols),\n",
        "        ('cat', categorical_transformer, cat_cols)\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "id": "Q7NYK2Nz69P-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cap_outliers(df, cols, lower=1, upper=99):\n",
        "    \"\"\"Caps outliers using percentile-based winsorization.\"\"\"\n",
        "    df = df.copy()\n",
        "    for c in cols:\n",
        "        lo, hi = df[c].quantile([lower/100, upper/100])\n",
        "        df[c] = df[c].clip(lo, hi)\n",
        "    return df\n",
        "\n",
        "# Apply capping ONLY on feature matrices (never on target or id)\n",
        "X = cap_outliers(X, num_cols)\n",
        "X_test = cap_outliers(X_test, num_cols)"
      ],
      "metadata": {
        "id": "z29aTGEk6_ax"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for col in num_cols[:6]:  # limit to avoid clutter\n",
        "    plt.figure(figsize=(5, 2))\n",
        "    sns.boxplot(x=X[col])\n",
        "    plt.title(f\"Boxplot: {col}\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "o7GqV5AE7Cue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(num_cols) > 1:\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    corr = X[num_cols].corr()\n",
        "    sns.heatmap(corr, cmap='coolwarm', center=0)\n",
        "    plt.title(\"Correlation Matrix (Numerical Features)\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "SNUbjxf77Ein"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if len(num_cols) <= 5:\n",
        "    sns.pairplot(train_df[num_cols.tolist() + [TARGET_COL]], hue=TARGET_COL)\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "oLIDC4Np7EfO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    'RandomForest': RandomForestClassifier(\n",
        "        n_estimators=500,\n",
        "        max_depth=None,\n",
        "        min_samples_split=5,\n",
        "        min_samples_leaf=2,\n",
        "        n_jobs=-1,\n",
        "        random_state=42\n",
        "    ),\n",
        "\n",
        "    'LightGBM': lgb.LGBMClassifier(\n",
        "        objective='multiclass',\n",
        "        n_estimators=700,\n",
        "        learning_rate=0.03,\n",
        "        num_leaves=31,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        random_state=42\n",
        "    ),\n",
        "\n",
        "    'XGBoost': xgb.XGBClassifier(\n",
        "        objective='multi:softprob',\n",
        "        eval_metric='mlogloss',\n",
        "        n_estimators=700,\n",
        "        learning_rate=0.03,\n",
        "        max_depth=6,\n",
        "        subsample=0.8,\n",
        "        colsample_bytree=0.8,\n",
        "        tree_method='hist',\n",
        "        random_state=42\n",
        "    )\n",
        "}\n"
      ],
      "metadata": {
        "id": "749SAF1q7Eca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "results = {}\n",
        "\n",
        "from sklearn.base import clone\n",
        "\n",
        "for name, model in models.items():\n",
        "    losses = []\n",
        "    for train_idx, val_idx in skf.split(X, y):\n",
        "        X_tr, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
        "        y_tr, y_val = y[train_idx], y[val_idx]\n",
        "\n",
        "        # IMPORTANT: clone model for each fold (fixes LightGBM/XGBoost feature mismatch)\n",
        "        model_clone = clone(model)\n",
        "\n",
        "        pipe = Pipeline(steps=[\n",
        "            ('preprocessor', preprocessor),\n",
        "            ('model', model_clone)\n",
        "        ])\n",
        "\n",
        "        pipe.fit(X_tr, y_tr)\n",
        "        val_pred = pipe.predict_proba(X_val)\n",
        "        losses.append(log_loss(y_val, val_pred))\n",
        "\n",
        "    results[name] = np.mean(losses)\n",
        "    print(f\"{name} CV LogLoss: {results[name]:.5f}\")\n",
        "\n"
      ],
      "metadata": {
        "id": "RBbm_yCk7L9n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "best_model_name = min(results, key=results.get)\n",
        "best_model = models[best_model_name]\n",
        "\n",
        "print(f\"\\nBest Model Selected: {best_model_name}\")"
      ],
      "metadata": {
        "id": "pQs3diO-7Ou-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "USE_CALIBRATION_FOR_LOGLOSS = True  # True for LogLoss, False for Accuracy/F1\n",
        "\n",
        "from sklearn.calibration import CalibratedClassifierCV\n",
        "\n",
        "if USE_CALIBRATION_FOR_LOGLOSS:\n",
        "    calibrated_model = CalibratedClassifierCV(\n",
        "        estimator=best_model,\n",
        "        method='isotonic',\n",
        "        cv=3\n",
        "    )\n",
        "\n",
        "    final_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', calibrated_model)\n",
        "    ])\n",
        "else:\n",
        "    final_pipeline = Pipeline(steps=[\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('model', best_model)\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "uEhKXYx17R3f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipeline.fit(X, y)"
      ],
      "metadata": {
        "id": "6oNwMbXx7VMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SUBMIT_PROBABILITIES = True   # True → log_loss submission\n",
        "SUBMIT_LABELS        = False  # True → accuracy / precision submission\n"
      ],
      "metadata": {
        "id": "2dSNS1Vf7V_s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_labels_enc = final_pipeline.predict(X_test)\n",
        "y_pred_prob = final_pipeline.predict_proba(X_test)"
      ],
      "metadata": {
        "id": "VZeCl9m57V6i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SUBMIT_PROBABILITIES:\n",
        "    # ---- GET ENCODED CLASS ORDER FROM MODEL ----\n",
        "    # predict_proba columns follow encoded class order: 0..K-1\n",
        "    n_classes = y_pred_prob.shape[1]\n",
        "    encoded_classes = np.arange(n_classes)\n",
        "\n",
        "    # ---- INVERSE TRANSFORM TO ORIGINAL LABELS ----\n",
        "    original_labels = label_encoder.inverse_transform(encoded_classes)\n",
        "\n",
        "    submission_cols = [f\"{TARGET_COL}_{cls}\" for cls in original_labels]\n",
        "\n",
        "    submission = pd.DataFrame(y_pred_prob, columns=submission_cols)\n",
        "    submission.insert(0, ID_COL, test_ids if test_ids is not None else range(len(submission)))\n",
        "\n",
        "    # ---- REORDER EXACTLY LIKE sample_submission.csv IF AVAILABLE ----\n",
        "    # try:\n",
        "    #     sample_sub = pd.read_csv('sample_submission.csv')\n",
        "    #     ordered_cols = sample_sub.columns.tolist()\n",
        "    #     submission = submission[ordered_cols]\n",
        "    #     print('Reordered columns using sample_submission.csv')\n",
        "    # except Exception:\n",
        "    #     print('sample_submission.csv not found – using inverse-transformed class order')\n",
        "\n",
        "    submission.to_csv('Submission.csv', index=False)\n",
        "    print('Submission.csv generated (probabilities)')\n",
        "    print(submission.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "terLUXUV7aqt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SUBMIT_PROBABILITIES:\n",
        "\n",
        "    n_classes = y_pred_prob.shape[1]\n",
        "    encoded_classes = np.arange(n_classes)\n",
        "\n",
        "    # ---- INVERSE TRANSFORM TO ORIGINAL LABELS ----\n",
        "    original_labels = label_encoder.inverse_transform(encoded_classes)\n",
        "\n",
        "    submission_cols = [f\"Status_{cls}\" for cls in original_labels]\n",
        "    submission_cols\n",
        "\n",
        "    submission = pd.DataFrame(y_pred_prob, columns=submission_cols)\n",
        "    submission.insert(0, ID_COL, test_ids if test_ids is not None else range(len(submission)))\n",
        "\n",
        "    # ---- REORDER EXACTLY LIKE sample_submission.csv IF AVAILABLE ----\n",
        "\n",
        "    # sample_sub = pd.read_csv(\"/kaggle/input/mle-ese-mock/submission (6).csv\")\n",
        "    # print(sample_sub.head());\n",
        "    # ordered_cols = sample_sub.columns.tolist()\n",
        "    # submission = submission[ordered_cols]\n",
        "    # print('Reordered columns using sample_submission.csv')\n",
        "\n",
        "    submission.to_csv('Submission.csv', index=False)\n",
        "    print('Submission.csv generated (probabilities)')\n",
        "    print(submission.head())\n",
        "\n"
      ],
      "metadata": {
        "id": "nCmXM7P-7pUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if SUBMIT_LABELS:\n",
        "    # • For accuracy / precision → use model.predict()\n",
        "\n",
        "    y_pred_labels = label_encoder.inverse_transform(y_pred_labels_enc)\n",
        "\n",
        "    labels_df = pd.DataFrame({\n",
        "        ID_COL: test_df[ID_COL],\n",
        "        f'{TARGET_COL}': y_pred_labels\n",
        "    })\n",
        "\n",
        "    labels_df.to_csv('Submission_labels.csv', index=False)\n",
        "    print('Submission_labels.csv generated (labels)')"
      ],
      "metadata": {
        "id": "x7b1LJ577c5H"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}