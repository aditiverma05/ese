{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# IMPORTS\n",
        "# ================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV, StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "\n",
        "# ================================\n",
        "# CONFIG\n",
        "# ================================\n",
        "TARGET = \"quality_grade\"\n",
        "RANDOM_STATE = 42\n",
        "\n",
        "# ================================\n",
        "# LOAD DATA\n",
        "# ================================\n",
        "train = pd.read_csv(\"/kaggle/input/mle-ese-mock/train (5).csv\")\n",
        "test  = pd.read_csv(\"/kaggle/input/mle-ese-mock/test (4).csv\")\n",
        "\n",
        "train_df = train.copy()\n",
        "test_df  = test.copy()\n",
        "\n",
        "print(\"Data loaded successfully\")"
      ],
      "metadata": {
        "id": "ch-TvQZn4327"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# SAVE ID & DROP\n",
        "# ================================\n",
        "test_id = test_df[\"id\"]\n",
        "train_df.drop(columns=[\"id\"], inplace=True)\n",
        "test_df.drop(columns=[\"id\"], inplace=True)"
      ],
      "metadata": {
        "id": "rKumhuCi435r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# ---------- EDA ----------\n",
        "# ================================\n",
        "# Missing values\n",
        "print(\"\\nMissing values per column:\")\n",
        "print(train_df.isnull().sum())\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "train_df.isnull().sum().plot(kind=\"bar\")\n",
        "plt.title(\"Missing Values per Column\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4nXnLUbU438j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Target distribution\n",
        "plt.figure(figsize=(8,4))\n",
        "sns.countplot(x=train_df[TARGET])\n",
        "plt.title(\"Target Distribution (quality_grade)\")\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ewp4SO2Z43_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nTarget distribution (normalized):\")\n",
        "print(train_df[TARGET].value_counts(normalize=True))"
      ],
      "metadata": {
        "id": "UbAmpD2544CA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# TARGET IMPUTATION (MODE)\n",
        "# ================================\n",
        "train_df[TARGET] = train_df[TARGET].fillna(train_df[TARGET].mode()[0])"
      ],
      "metadata": {
        "id": "OhzALvrk44Eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# SPLIT X & y\n",
        "# ================================\n",
        "X = train_df.drop(columns=[TARGET])\n",
        "y = train_df[TARGET]"
      ],
      "metadata": {
        "id": "WSxQqyZc44IA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# COLUMN TYPES\n",
        "# ================================\n",
        "num_cols = X.select_dtypes(include=np.number).columns.tolist()\n",
        "cat_cols = X.select_dtypes(exclude=np.number).columns.tolist()"
      ],
      "metadata": {
        "id": "4or0gRID5Mq5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# IMPUTATION\n",
        "# ================================\n",
        "num_imputer = SimpleImputer(strategy=\"median\")\n",
        "X[num_cols] = num_imputer.fit_transform(X[num_cols])\n",
        "test_df[num_cols] = num_imputer.transform(test_df[num_cols])\n",
        "\n",
        "cat_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "X[cat_cols] = cat_imputer.fit_transform(X[cat_cols])\n",
        "test_df[cat_cols] = cat_imputer.transform(test_df[cat_cols])"
      ],
      "metadata": {
        "id": "Yj-aR90B5QPB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# ONE HOT ENCODING\n",
        "# ================================\n",
        "ohe = OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
        "X_cat = ohe.fit_transform(X[cat_cols])\n",
        "test_cat = ohe.transform(test_df[cat_cols])\n",
        "\n",
        "X_cat_df = pd.DataFrame(X_cat, columns=ohe.get_feature_names_out(cat_cols), index=X.index)\n",
        "test_cat_df = pd.DataFrame(test_cat, columns=ohe.get_feature_names_out(cat_cols), index=test_df.index)\n",
        "\n",
        "X = pd.concat([X.drop(columns=cat_cols), X_cat_df], axis=1)\n",
        "test_df = pd.concat([test_df.drop(columns=cat_cols), test_cat_df], axis=1)"
      ],
      "metadata": {
        "id": "GIOQkkQP5SlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# TRAIN / VALID SPLIT\n",
        "# ================================\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X, y, test_size=0.2, stratify=y, random_state=RANDOM_STATE\n",
        ")"
      ],
      "metadata": {
        "id": "5oLYDlh05Uqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# RANDOM FOREST + RANDOMIZED SEARCH\n",
        "# ================================\n",
        "rf = RandomForestClassifier(class_weight=\"balanced\", random_state=RANDOM_STATE, n_jobs=-1)\n",
        "\n",
        "param_dist = {\n",
        "    \"n_estimators\": [200, 400, 600, 800],\n",
        "    \"max_depth\": [None, 10, 20, 25],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4],\n",
        "    \"max_features\": [\"sqrt\", \"log2\"]\n",
        "}\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
        "\n",
        "search = RandomizedSearchCV(\n",
        "    estimator=rf,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=25,\n",
        "    scoring=\"f1_macro\",\n",
        "    cv=cv,\n",
        "    random_state=RANDOM_STATE,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"\\nTraining RandomForest with RandomizedSearchCV...\")\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "best_model = search.best_estimator_\n",
        "print(\"\\nBest Parameters Found:\")\n",
        "print(search.best_params_)"
      ],
      "metadata": {
        "id": "HSSwAqo75ZeY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# VALIDATION METRICS\n",
        "# ================================\n",
        "pred_valid = best_model.predict(X_valid)\n",
        "print(\"\\nValidation Accuracy:\", accuracy_score(y_valid, pred_valid))\n",
        "print(\"Macro F1 Score:\", f1_score(y_valid, pred_valid, average=\"macro\"))\n",
        "print(\"\\nClassification Report:\\n\")\n",
        "print(classification_report(y_valid, pred_valid))\n"
      ],
      "metadata": {
        "id": "U-xWuDMu5c92"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# ALIGN TEST FEATURES\n",
        "# ================================\n",
        "test_df = test_df[X_train.columns]\n",
        "\n",
        "# ================================\n",
        "# TEST PREDICTION\n",
        "# ================================\n",
        "test_probs = best_model.predict_proba(test_df)\n",
        "classes = best_model.classes_\n",
        "\n",
        "# ================================\n",
        "# SUBMISSION FILE\n",
        "# ================================\n",
        "submission = pd.DataFrame(test_probs, columns=[f\"Status_{c}\" for c in classes])\n",
        "submission.insert(0, \"id\", test_id)\n",
        "\n",
        "submission.to_csv(\"submission.csv\", index=False)\n",
        "print(\"\\nsubmission.csv saved successfully!\")"
      ],
      "metadata": {
        "id": "SBRkTSrG5gNY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O-YHDMc05h0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8cOrdx9i5hxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "CmbOQPiZ5huN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UCjoEv4y5hrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5Pvesf3B5hoi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# TEST PREDICTION (LABELS)\n",
        "# ================================\n",
        "# predict class labels directly\n",
        "test_labels = best_model.predict(test_df)\n",
        "\n",
        "# ================================\n",
        "# LABEL SUBMISSION FILE\n",
        "# ================================\n",
        "submission_labels = pd.DataFrame({\n",
        "    \"id\": test_id,\n",
        "    \"Status\": test_labels  # predicted labels in one column\n",
        "})\n",
        "\n",
        "submission_labels.to_csv(\"submission_labels.csv\", index=False)\n",
        "print(\"\\nsubmission_labels.csv saved successfully!\")\n",
        "print(submission_labels.head())\n"
      ],
      "metadata": {
        "id": "OoWoHm955hl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QNAtsE0-5hi-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_tMBuXrq5m_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0028B3575m7p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QrZGASyC5m5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# TEST PREDICTION (PROBABILITIES)\n",
        "# ================================\n",
        "test_probs = best_model.predict_proba(test_df)  # shape: [n_samples, n_classes]\n",
        "classes = best_model.classes_\n",
        "\n",
        "# Create submission DataFrame\n",
        "submission = pd.DataFrame(\n",
        "    test_probs,\n",
        "    columns=[f\"quality_grade_{c}\" for c in classes]  # probabilities per class\n",
        ")\n",
        "\n",
        "submission.insert(0, \"id\", test_id)\n",
        "\n",
        "# Save submission\n",
        "submission.to_csv(\"sub_probs.csv\", index=False)\n",
        "print(\"\\nsub_probs.csv saved successfully!\")\n",
        "print(submission.head())\n"
      ],
      "metadata": {
        "id": "004KykrZ5m2k"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}